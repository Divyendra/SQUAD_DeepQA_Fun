{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQUAD Question Answering Dataset - Basic RNN\n",
    "SQUAD - Stanford Question Answering Dataset is a new reading comprehension dataset. It consists of questions posed by crowd workers on a set of wikipedia articles where the answer to every question is a segment o text, or span, from the corresponding reading passage. There are 1,00,000+ question answer pairs on 500+ articles. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formal definition of the SQUAD Question answering dataset\n",
    "1. Given a three tuple (Q,P,($a_{s},a_{e}$)), where Q is the question, P is the context paragraph and $a_{s}$ and $a_{e}$ are the start and end indices. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process\n",
    "1. Both the question and the context vectors are first encoded into a LSTM. \n",
    "2. Word embeddings are passed onto the encoder that generated an attention vector which the decoder decodes to produce the final output. \n",
    "3. Can use 100 dimensional glove embeddings. \n",
    "4. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function for the SQUAD Model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "1. Dataset importing from JSON format\n",
    "2. Extracting data.\n",
    "3. Downloading the Glove Vector model for the Word 2 vectors. Try with the 50 length vector first and then increase that. \n",
    "4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from utils import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "Q_SIZE = 40  #Upper bound of max question size\n",
    "C_SIZE = 300 #Upper bound of max context size\n",
    "\n",
    "## RNN Model Parameters\n",
    "DATA_CAP = None\n",
    "batch_size = 64\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Glove vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "W2VEC_LEN = 50\n",
    "GLOVE_path = \"./preprocessing/data/glove.6B/glove.6B.50d.txt\"\n",
    "reader = csv.reader(open(GLOVE_path), delimiter=' ', quoting=csv.QUOTE_NONE) \n",
    "W2VEC = {line[0]: np.array(list(map(float, line[1: ]))) for line in reader}\n",
    "del csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize(sent, fill, clean=False):\n",
    "    \"\"\"Takes a sentence and returns corresponing list of GloVecs\n",
    "    @return (ndarray of glovecs, actual_length)\n",
    "    \"\"\"\n",
    "    if clean:\n",
    "        pass #sent = _dataCleaning(sent)\n",
    "    words = sent.split(\" \")\n",
    "    words = words[:fill]  #Capping the context. Beware!!\n",
    "    vecs = np.empty((1,W2VEC_LEN))\n",
    "    for w in words:\n",
    "        vec = W2VEC.get(w.lower(), None)\n",
    "        if vec is None:\n",
    "            vec = np.random.rand(W2VEC_LEN)\n",
    "        vec = vec.reshape((1,W2VEC_LEN))\n",
    "        vecs = np.concatenate((vecs, vec), axis=0)\n",
    "    \n",
    "    PADDING = np.zeros((1, W2VEC_LEN))\n",
    "    for _ in np.arange(fill - len(words)):\n",
    "        vecs = np.concatenate((vecs, PADDING), axis=0)\n",
    "    return vecs[1:], len(words)\n",
    "\n",
    "def _dataCleaning(string):\n",
    "    strip_special_chars = re.compile(\"[^A-Za-z0-9 ]+\")\n",
    "    string = string.replace(\"<br />\", \" \")\n",
    "    string = string.replace(\"''\", '\" ')\n",
    "    string = string.replace(\"``\", '\" ')\n",
    "    return re.sub(strip_special_chars, \"\", string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset for questions and answers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Entries#:All should be same: 81403 81403 81403 81403\n"
     ]
    }
   ],
   "source": [
    "## Loading the dataset here. \n",
    "from itertools import izip\n",
    "path = \"./preprocessing/data/squad/\"\n",
    "#Paths\n",
    "q_p = \"train.question\"; c_p = \"train.context\"; s_p = \"train.span\"\n",
    "#Lines\n",
    "q_l = []; c_l = []; s_l = []\n",
    "\n",
    "itr = 0\n",
    "with open(path+q_p) as q_f, \\\n",
    "     open(path+c_p) as c_f, \\\n",
    "     open(path+s_p) as s_f:\n",
    "    for q, c, s in izip(q_f, c_f, s_f):\n",
    "        c = _dataCleaning(c)\n",
    "        q_l.append(q), c_l.append(c); s_l.append(s)\n",
    "        itr += 1\n",
    "\n",
    "print(\"#Entries#:All should be same:\", itr, len(q_l), len(c_l), len(s_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorise all Questions and Contexts\n",
    "def get_batch(cnt=64, filtr=True):\n",
    "    \"\"\"\n",
    "    @param filtr: Filters only entries with context less than C_SIZE\n",
    "    \n",
    "    Returns Batch of 'cnt' elements from the dataset as vectorized numpy arrays\n",
    "    @return: (questions, answers, labels, ids) : The first three being numpy vectorised arrays.\n",
    "                                                'ids' is a list of corresponding entry ids in q_l,c_l,s_l\n",
    "                                                questions shape would be (cnt, Q_SIZE, W2VEC_LEN)\n",
    "    Each entry of labels is a one-hot repr of span given\n",
    "    \n",
    "    The numpy concatenate function copies at every call and hence is 10X slower for large batches.\n",
    "    Traditional Python lists append is a better fit here.\n",
    "    \"\"\"\n",
    "    N = (len(q_l) if DATA_CAP is None else DATA_CAP)\n",
    "    batch_ids = list(np.random.randint(0, N+1, cnt))\n",
    "    rmv_ids = []\n",
    "    q_vecs = []; c_vecs = []; label_vecs = []; q_lens = []; c_lens = []\n",
    "\n",
    "    #q_vecs = np.empty((1, Q_SIZE, W2VEC_LEN)); c_vecs = np.empty((1, C_SIZE, W2VEC_LEN))\n",
    "    for idx in batch_ids:\n",
    "        #q_vec = vectorize(q_l[idx], fill=Q_SIZE).reshape((1, Q_SIZE, W2VEC_LEN))\n",
    "        #q_vecs = np.concatenate((q_vecs, q_vec), axis=0)\n",
    "        #c_vec = vecty\n",
    "        #vecorize(c_l[idx], fill=C_SIZE).reshape((1, C_SIZE, W2VEC_LEN))\n",
    "        #c_vecs = np.concatenate((c_vecs, c_vec), axis=0)\n",
    "        span = map(int, s_l[idx].split())\n",
    "        try:\n",
    "            if span[1] >= C_SIZE and filtr:\n",
    "                replacement = np.random.randint(0, N+1, 1)[0]\n",
    "                rmv_ids.append(idx)\n",
    "                batch_ids.append(replacement)\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            print(e, \"id:\", idx)\n",
    "            continue\n",
    "        q_vec, q_actual_len = vectorize(q_l[idx], fill=Q_SIZE)\n",
    "        q_vecs.append(q_vec); q_lens.append(q_actual_len)\n",
    "        c_vec, c_actual_len = vectorize(c_l[idx], fill=C_SIZE, clean=True)\n",
    "        c_vecs.append(c_vec); c_lens.append(c_actual_len)\n",
    "        \n",
    "        label_vec = np.zeros(2*C_SIZE) #start_end_vec + end_span_vec\n",
    "        idx = [span[0], C_SIZE + span[1]]\n",
    "        label_vec[idx] = 1\n",
    "        label_vecs.append(label_vec)\n",
    "\n",
    "    q_vecs = np.array(q_vecs); c_vecs = np.array(c_vecs); label_vecs = np.array(label_vecs)\n",
    "    q_lens = np.array(q_lens); c_lens = np.array(c_lens)\n",
    "    \n",
    "    batch_ids = set(batch_ids); rmv_ids = set(rmv_ids)\n",
    "    final_ids = batch_ids.difference(rmv_ids)\n",
    "    return (q_vecs, q_lens), (c_vecs, c_lens), label_vecs, final_ids\n",
    "    #print(q_vecs.shape, c_vecs.shape, label_vecs.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max question: 60 MAx context: 655 Max span: 605\n"
     ]
    }
   ],
   "source": [
    "context_lengths = []\n",
    "question_lengths = []\n",
    "span_indxs = []\n",
    "\n",
    "for i in range(len(c_l)):\n",
    "    context_lengths.append(len(c_l[i].split()))\n",
    "\n",
    "for i in range(len(q_l)):\n",
    "    question_lengths.append(len(q_l[i].split()))\n",
    "\n",
    "for i in range(len(s_l)):\n",
    "    span_indxs.append(int(s_l[i].split()[1]))\n",
    "    \n",
    "print(\"Max question:\", max(question_lengths), \"MAx context:\", max(context_lengths), \"Max span:\", max(span_indxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(context_lengths)\n",
    "plt.title(\"Context Lengths distribution\")\n",
    "# plt.show()\n",
    "plt.hist(question_lengths)\n",
    "plt.title(\"Question Lengths distribution\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.hist(answer_lengths)\n",
    "# plt.title(\"Answer Lengths distribution\")\n",
    "# plt.show()\n",
    "del plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model the generator for the tensorflow model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "st = \"\"\"def generator(samples, session, batch_size = 32):\n",
    "    num_samples = len(samples)\n",
    "    \n",
    "    while 1:\n",
    "        sklearn.utils.shuffle(samples)\n",
    "        \n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "            labels = []\n",
    "            reviews_embeddings = []\n",
    "            \n",
    "            for batch_sample in batch_samples:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyRNNCell(tf.nn.rnn_cell.RNNCell):\n",
    "  \"\"\"The most basic RNN cell.\n",
    "  Args:\n",
    "    num_units: int, The number of units in the RNN cell.\n",
    "    activation: Nonlinearity to use.  Default: `tanh`.\n",
    "    reuse: (optional) Python boolean describing whether to reuse variables\n",
    "     in an existing scope.  If not `True`, and the existing scope already has\n",
    "     the given variables, an error is raised.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, num_units, activation=None, reuse=None):\n",
    "    super(MyRNNCell, self).__init__(_reuse=reuse)\n",
    "    self._num_units = num_units\n",
    "\n",
    "  @property\n",
    "  def state_size(self):\n",
    "    return self._num_units\n",
    "\n",
    "  @property\n",
    "  def output_size(self):\n",
    "    return self._num_units\n",
    "\n",
    "  def call(self, inputs, state):\n",
    "    \"\"\"Most basic RNN: output = new_state = act(W * input + U * state + B).\"\"\"\n",
    "    \n",
    "    # reshape vectors to matrices\n",
    "    state_prev = tf.reshape(state, [1, self.state_size])\n",
    "    x = tf.reshape(x, [1,state_size])\n",
    "    # initializer\n",
    "    xav_init = tf.contrib.layers.xavier_initializer\n",
    "    # params\n",
    "    Whh = tf.get_variable('Whh', shape=[hsize, hsize], initializer=xav_init())\n",
    "    Wih = tf.get_variable('Wih', shape=[state_size, hsize], initializer=xav_init())\n",
    "    b = tf.get_variable('b', shape=[hsize], initializer=tf.constant_initializer(0.001))\n",
    "    \n",
    "    \n",
    "    # current hidden state\n",
    "    h = tf.tanh(tf.matmul(hprev, W) + tf.matmul(x,U) + b)\n",
    "    h = tf.reshape(h, [hsize])\n",
    "\n",
    "    output = tf.tanh(tf.matmul(state, W_h) + tf.matmul(inputs, W_x) + b) #_linear([inputs, state], self._num_units, True))\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Question Module\n",
    "q_state_sz = 64\n",
    "\n",
    "def question_module(init_state=None):\n",
    "    '''\n",
    "    @arg init_state :tf.Tensor of shape (batch_size, q_state_sz)\n",
    "    \n",
    "    @return (op, state, c_batch) where op(output) and state are of shape (batch_size, q_state_sz)\n",
    "            and q_batch is the question_batched input placeholder\n",
    "    '''\n",
    "    q_batch = tf.placeholder(tf.float32, [Q_SIZE, batch_size, W2VEC_LEN])\n",
    "    seq_lens = tf.placeholder(tf.int32, [batch_size,])\n",
    "\n",
    "    #Define RNN Cell\n",
    "    q_cell = tf.nn.rnn_cell.BasicRNNCell(q_state_sz)\n",
    "    #LSTM version: Note that the state o/p of LSTM is different: It is a LSTMStateTuple:(cell, state)\n",
    "    #q_cell = tf.nn.rnn_cell.BasicLSTMCell(q_state_sz, forget_bias=1.0)\n",
    "    \n",
    "    #Default initial state is all zeros\n",
    "    outputs, state = tf.nn.dynamic_rnn(q_cell, q_batch,\n",
    "                                      initial_state=init_state,\n",
    "                                      dtype=tf.float32, time_major=True,\n",
    "                                      sequence_length=seq_lens)\n",
    "\n",
    "    return outputs, state, q_batch, seq_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Context Module\n",
    "c_state_sz = 64\n",
    "def context_module(init_state):\n",
    "    '''\n",
    "    @arg init_state :tf.Tensor of shape (batch_size, c_state_sz)\n",
    "\n",
    "    @return (op, state, c_batch) where op(output) and state are of shape (batch_size, c_state_sz)\n",
    "            and c_batch is the context_batched input placeholder\n",
    "    '''\n",
    "    if init_state is None: raise ValueError(\"Dnt Kid me!!. Give a state\")\n",
    "    c_batch = tf.placeholder(tf.float32, [C_SIZE, batch_size, W2VEC_LEN])\n",
    "    seq_lens = tf.placeholder(tf.int32, [batch_size,])\n",
    "    \n",
    "    context_cell = tf.nn.rnn_cell.BasicRNNCell(c_state_sz)\n",
    "    #LSTM version: Note that the state o/p of LSTM is different: It is a LSTMStateTuple:(cell, state)\n",
    "    #context_cell = tf.nn.rnn_cell.BasicLSTMCell(c_state_sz, forget_bias=1.0)\n",
    "\n",
    "#     outputs, state = tf.nn.static_rnn(context_cell, x,\n",
    "#                                        initial_state=init_state,\n",
    "#                                        dtype=tf.float32)\n",
    "    outputs, state = tf.nn.dynamic_rnn(context_cell, c_batch,\n",
    "                                  initial_state=init_state,\n",
    "                                  dtype=tf.float32, time_major=True,\n",
    "                                  sequence_length=seq_lens)\n",
    "\n",
    "\n",
    "    return outputs, state, c_batch, seq_lens\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Answer Module\n",
    "def _init_wts(shape):\n",
    "    bound = np.sqrt(6.0 / sum(shape))\n",
    "    wts = tf.random_uniform(shape, minval=-bound, maxval=bound, dtype=tf.float32)\n",
    "    #wts = tf.random_normal(shape, stddev=np.sqrt(2.0 / np.sum(shape)), dtype=tf.float64)\n",
    "    return tf.Variable(wts)\n",
    "\n",
    "def _init_bias(sz):\n",
    "    b = np.ones(sz)*0.001\n",
    "    return tf.Variable(b, dtype=tf.float32)\n",
    "\n",
    "def answer_module(ip_state, layers=[1024, 256]):\n",
    "    '''\n",
    "    ip_state: tf.Tensor of shape (batch_sz, C_SIZE)\n",
    "    layers: List of hidden_layer sizes to be used\n",
    "    \n",
    "    @return: tf.Tensor variables of loss gradient and loss and labes placeholder\n",
    "    '''\n",
    "    prev_feature_sz = c_state_sz\n",
    "    conditioned_state =  ip_state  #State(Context|Question)\n",
    "\n",
    "    X = conditioned_state\n",
    "    \n",
    "    for layer in layers:\n",
    "        w = _init_wts((prev_feature_sz, layer))\n",
    "        b = _init_bias(layer)\n",
    "        prev_feature_sz = layer\n",
    "        h_l = tf.nn.relu(tf.matmul(X, w) + b)\n",
    "        X = h_l\n",
    "    \n",
    "    #Final O/P layer\n",
    "    w_s = _init_wts((prev_feature_sz, C_SIZE)); b_s = _init_bias(C_SIZE)\n",
    "    w_e = _init_wts((prev_feature_sz, C_SIZE)); b_e = _init_bias(C_SIZE)\n",
    "    \n",
    "    logits_s = tf.matmul(X, w_s) + b_s\n",
    "    logits_e = tf.matmul(X, w_e) + b_e\n",
    "\n",
    "    return logits_s, logits_e\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_fn(logits_s, logits_e):\n",
    "    labels_holder = tf.placeholder(tf.float32, shape=(2, batch_size, C_SIZE))\n",
    "    loss_s = tf.nn.softmax_cross_entropy_with_logits(logits=logits_s, labels=labels_holder[0,:])\n",
    "    loss_e  = tf.nn.softmax_cross_entropy_with_logits(logits=logits_e, labels=labels_holder[1,:])\n",
    "    \n",
    "    probs_s = tf.nn.softmax(logits_s)\n",
    "    probs_e = tf.nn.softmax(logits_e)\n",
    "    preds_s = tf.argmax(probs_s, axis=1)\n",
    "    preds_e = tf.argmax(probs_e, axis=1)\n",
    "    \n",
    "    loss_s_mean = tf.reduce_mean(loss_s)\n",
    "    loss_e_mean  = tf.reduce_mean(loss_e)\n",
    "    loss = tf.add(loss_s_mean, loss_e_mean)\n",
    "    \n",
    "    #optimizer = tf.train.GradientDescentOptimizer(learning_rate = 1e-5).minimize(loss)\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    loss_grad = optimizer.minimize(loss)  #Gradient Clipping is part of it    \n",
    "    \n",
    "    return loss_grad, loss, labels_holder, preds_s, preds_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BUILD the Computational graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.variable_scope(\"question_module\"):\n",
    "    q_ops, q_state, q_batch_ip, q_seq_lens_holder = question_module(None)\n",
    "with tf.variable_scope(\"context_module\"):\n",
    "    c_ops, c_state, c_batch_ip, c_seq_lens_holder = context_module(q_state)\n",
    "with tf.variable_scope(\"answer_module\"):\n",
    "    logits_s, logits_e = answer_module(c_state)\n",
    "with tf.variable_scope(\"loss_module\"):\n",
    "    loss_grad_train, loss_train, labels_ip_train, preds_s, preds_e = loss_fn(logits_s, logits_e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 1.3004876286363598)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluate a random sample and get metrics\n",
    "def get_metrics(dataset, sess=None, sample=100):\n",
    "    '''\n",
    "    @param dataset: tuple of (List of questions, List of contexts, List of spans)\n",
    "    '''\n",
    "    q_l, c_l, s_l = dataset\n",
    "    \n",
    "    #Placeholders to be filled: q_batch_ip, q_seq_lens_holder, c_seq_lens_holder, c_batch_ip, labels_ip_train\n",
    "    \n",
    "    if sess == None: \n",
    "        sess = tf.Session()\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        \n",
    "    (q_vecs, q_lens), (c_vecs, c_lens), label_vecs, idx = get_batch(cnt=batch_size)\n",
    "    \n",
    "    q_vecs_ip = q_vecs.transpose(1,0,2) #To make it to (time_steps, batch_size, word_vec_len_features) shape\n",
    "    c_vecs_ip = c_vecs.transpose(1,0,2) #To make it to (time_steps, batch_size, word_vec_len_features) shape\n",
    "    label_vecs = label_vecs.reshape(2, batch_size, C_SIZE)\n",
    "    \n",
    "    start, end = sess.run([preds_s, preds_e], feed_dict={q_batch_ip : q_vecs_ip,\n",
    "                                              q_seq_lens_holder : q_lens,\n",
    "                                              c_seq_lens_holder : c_lens,\n",
    "                                              c_batch_ip : c_vecs_ip,\n",
    "                                              labels_ip_train: label_vecs})\n",
    "    \n",
    "    em_scr = 0; f1_scr = 0\n",
    "    for _id, (s, e) in enumerate(zip(start, end)):\n",
    "        pred_ans_sent = get_answer_txt(s, e, c_l[_id])\n",
    "        gs, ge = map(int, s_l[_id].split())\n",
    "        ground_truth  = get_answer_txt(gs, ge, c_l[_id])\n",
    "        em_scr += exact_match_score(pred_ans_sent, ground_truth)\n",
    "        f1_scr += f1_score(pred_ans_sent, ground_truth)\n",
    "    \n",
    "    return em_scr, f1_scr\n",
    "        \n",
    "# get_metrics((q_l, c_l, s_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "0  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  \n",
      "Itr: 20, Loss:11.435, Time:5.08967590332\n",
      "20  21  22  23  24  25  26  27  28  29  30  31  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-224-9817fdb90c8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-224-9817fdb90c8a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m                                                   \u001b[0mc_seq_lens_holder\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mc_lens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                                                   \u001b[0mc_batch_ip\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mc_vecs_ip\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                                                   labels_ip_train : label_vecs})\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mitr\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mitr\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m20\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "import time\n",
    "\n",
    "def train():\n",
    "    N = (len(q_l) if DATA_CAP is None else DATA_CAP)\n",
    "    itr = 0\n",
    "    \n",
    "    for _ in range(num_epochs):\n",
    "        print(\"Epoch: \", _)\n",
    "        st = time.time()\n",
    "        for batches in np.arange(N/batch_size):\n",
    "            print(batches,\" \", end=\"\")\n",
    "\n",
    "            (q_vecs, q_lens), (c_vecs, c_lens), label_vecs, _ = get_batch(cnt=batch_size)\n",
    "            q_vecs_ip = q_vecs.transpose(1,0,2) #To make it to (time_steps, batch_size, word_vec_len_features) shape\n",
    "            c_vecs_ip = c_vecs.transpose(1,0,2) #To make it to (time_steps, batch_size, word_vec_len_features) shape\n",
    "            label_vecs = label_vecs.reshape(2, batch_size, C_SIZE)\n",
    "#             print(sess.run(c_state, feed_dict={q_batch_ip : q_vecs_ip,\n",
    "#                                                c_batch_ip : c_vecs_ip}))\n",
    "#             sess.run(q_state, feed_dict={q_batch_ip : q_vecs_ip,\n",
    "#                                            c_batch_ip : c_vecs_ip,\n",
    "#                                            labels_ip_train : label_vecs})\n",
    "            \n",
    "            ret = sess.run(loss_train, feed_dict={q_batch_ip : q_vecs_ip,\n",
    "                                                  q_seq_lens_holder : q_lens,\n",
    "                                                  c_seq_lens_holder : c_lens,\n",
    "                                                  c_batch_ip : c_vecs_ip,\n",
    "                                                  labels_ip_train : label_vecs})\n",
    "            itr += 1\n",
    "            if itr % 20 == 0:\n",
    "                end = time.time()\n",
    "                loss = sess.run(loss_train, feed_dict={q_batch_ip : q_vecs_ip,\n",
    "                                                       q_seq_lens_holder : q_lens, \n",
    "                                                       c_seq_lens_holder : c_lens,\n",
    "                                                       c_batch_ip : c_vecs_ip,\n",
    "                                                       labels_ip_train : label_vecs})\n",
    "                print(\"\\nItr: %s, Loss:%s, Time:%s\"%(itr, loss, end-st))\n",
    "                st = end\n",
    "\n",
    "#tf.reset_default_graph()\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
