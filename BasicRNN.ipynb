{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQUAD Question Answering Dataset - Basic RNN\n",
    "SQUAD - Stanford Question Answering Dataset is a new reading comprehension dataset. It consists of questions posed by crowd workers on a set of wikipedia articles where the answer to every question is a segment o text, or span, from the corresponding reading passage. There are 1,00,000+ question answer pairs on 500+ articles. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formal definition of the SQUAD Question answering dataset\n",
    "1. Given a three tuple (Q,P,($a_{s},a_{e}$)), where Q is the question, P is the context paragraph and $a_{s}$ and $a_{e}$ are the start and end indices. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process\n",
    "1. Both the question and the context vectors are first encoded into a LSTM. \n",
    "2. Word embeddings are passed onto the encoder that generated an attention vector which the decoder decodes to produce the final output. \n",
    "3. Can use 100 dimensional glove embeddings. \n",
    "4. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function for the SQUAD Model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "1. Dataset importing from JSON format\n",
    "2. Extracting data.\n",
    "3. Downloading the Glove Vector model for the Word 2 vectors. Try with the 50 length vector first and then increase that. \n",
    "4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from utils import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "Q_SIZE = 40  #Upper bound of max question size\n",
    "C_SIZE = 500 #Upper bound of max context size\n",
    "\n",
    "## RNN Model Parameters\n",
    "DATA_CAP = None\n",
    "batch_size = 64\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Glove vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "W2VEC_LEN = 50\n",
    "GLOVE_path = \"./preprocessing/data/glove.6B/glove.6B.50d.txt\"\n",
    "reader = csv.reader(open(GLOVE_path), delimiter=' ', quoting=csv.QUOTE_NONE) \n",
    "W2VEC = {line[0]: np.array(list(map(float, line[1: ]))) for line in reader}\n",
    "del csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize(sent, fill, clean=False):\n",
    "    \"\"\"Takes a sentence and returns corresponing list of GloVecs\n",
    "    @return (ndarray of glovecs, actual_length)\n",
    "    \"\"\"\n",
    "    if clean:\n",
    "        pass #sent = _dataCleaning(sent)\n",
    "    words = sent.split(\" \")\n",
    "    words = words[:fill]  #Capping the context. Beware!!\n",
    "    vecs = np.empty((1,W2VEC_LEN))\n",
    "    for w in words:\n",
    "        vec = W2VEC.get(w.lower(), None)\n",
    "        if vec is None:\n",
    "            vec = np.random.rand(W2VEC_LEN)\n",
    "        vec = vec.reshape((1,W2VEC_LEN))\n",
    "        vecs = np.concatenate((vecs, vec), axis=0)\n",
    "    \n",
    "    PADDING = np.zeros((1, W2VEC_LEN))\n",
    "    for _ in np.arange(fill - len(words)):\n",
    "        vecs = np.concatenate((vecs, PADDING), axis=0)\n",
    "    return vecs[1:], len(words)\n",
    "\n",
    "def _dataCleaning(string):\n",
    "    strip_special_chars = re.compile(\"[^A-Za-z0-9 ]+\")\n",
    "    string = string.replace(\"<br />\", \" \")\n",
    "    string = string.replace(\"''\", '\" ')\n",
    "    string = string.replace(\"``\", '\" ')\n",
    "    return re.sub(strip_special_chars, \"\", string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset for questions and answers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Entries#:All should be same: 81403 81403 81403 81403\n"
     ]
    }
   ],
   "source": [
    "## Loading the dataset here. \n",
    "from itertools import izip\n",
    "path = \"./preprocessing/data/squad/\"\n",
    "#Paths\n",
    "q_p = \"train.question\"; c_p = \"train.context\"; s_p = \"train.span\"\n",
    "#Lines\n",
    "q_l = []; c_l = []; s_l = []\n",
    "\n",
    "itr = 0\n",
    "with open(path+q_p) as q_f, \\\n",
    "     open(path+c_p) as c_f, \\\n",
    "     open(path+s_p) as s_f:\n",
    "    for q, c, s in izip(q_f, c_f, s_f):\n",
    "        c = _dataCleaning(c)\n",
    "        q_l.append(q), c_l.append(c); s_l.append(s)\n",
    "        itr += 1\n",
    "\n",
    "print(\"#Entries#:All should be same:\", itr, len(q_l), len(c_l), len(s_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Vectorise all Questions and Contexts\n",
    "def get_batch(cnt=64, filtr=True):\n",
    "    \"\"\"\n",
    "    @param filtr: Filters only entries with context less than C_SIZE\n",
    "    \n",
    "    Returns Batch of 'cnt' elements from the dataset as vectorized numpy arrays\n",
    "    @return: (questions, answers, labels, ids) : The first three being numpy vectorised arrays.\n",
    "                                                'ids' is a list of corresponding entry ids in q_l,c_l,s_l\n",
    "                                                questions shape would be (cnt, Q_SIZE, W2VEC_LEN)\n",
    "    Each entry of labels is a one-hot repr of span given\n",
    "    \n",
    "    The numpy concatenate function copies at every call and hence is 10X slower for large batches.\n",
    "    Traditional Python lists append is a better fit here.\n",
    "    \"\"\"\n",
    "    N = (len(q_l) if DATA_CAP is None else DATA_CAP)\n",
    "    batch_ids = list(np.random.randint(0, N, cnt))\n",
    "    rmv_ids = []\n",
    "    q_vecs = []; c_vecs = []; label_vecs = []; q_lens = []; c_lens = []\n",
    "\n",
    "    #q_vecs = np.empty((1, Q_SIZE, W2VEC_LEN)); c_vecs = np.empty((1, C_SIZE, W2VEC_LEN))\n",
    "    for idx in batch_ids:\n",
    "        #q_vec = vectorize(q_l[idx], fill=Q_SIZE).reshape((1, Q_SIZE, W2VEC_LEN))\n",
    "        #q_vecs = np.concatenate((q_vecs, q_vec), axis=0)\n",
    "        #c_vec = vecty\n",
    "        #vecorize(c_l[idx], fill=C_SIZE).reshape((1, C_SIZE, W2VEC_LEN))\n",
    "        #c_vecs = np.concatenate((c_vecs, c_vec), axis=0)\n",
    "        span = map(int, s_l[idx].split())\n",
    "        try:\n",
    "            if span[1] >= C_SIZE and filtr:\n",
    "                replacement = np.random.randint(0, N, 1)[0]\n",
    "                rmv_ids.append(idx)\n",
    "                batch_ids.append(replacement)\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            print(e, \"id:\", idx)\n",
    "            continue\n",
    "        q_vec, q_actual_len = vectorize(q_l[idx], fill=Q_SIZE)\n",
    "        q_vecs.append(q_vec); q_lens.append(q_actual_len)\n",
    "        c_vec, c_actual_len = vectorize(c_l[idx], fill=C_SIZE, clean=True)\n",
    "        c_vecs.append(c_vec); c_lens.append(c_actual_len)\n",
    "        \n",
    "        label_vec = np.zeros(2*C_SIZE) #start_end_vec + end_span_vec\n",
    "        idx = [span[0], C_SIZE + span[1]]\n",
    "        label_vec[idx] = 1\n",
    "        label_vecs.append(label_vec)\n",
    "\n",
    "    q_vecs = np.array(q_vecs); c_vecs = np.array(c_vecs); label_vecs = np.array(label_vecs)\n",
    "    q_lens = np.array(q_lens); c_lens = np.array(c_lens)\n",
    "    \n",
    "    batch_ids = set(batch_ids); rmv_ids = set(rmv_ids)\n",
    "    final_ids = batch_ids.difference(rmv_ids)\n",
    "    return (q_vecs, q_lens), (c_vecs, c_lens), label_vecs, final_ids\n",
    "    #print(q_vecs.shape, c_vecs.shape, label_vecs.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max question: 60 MAx context: 655 Max span: 605\n"
     ]
    }
   ],
   "source": [
    "context_lengths = []\n",
    "question_lengths = []\n",
    "span_indxs = []\n",
    "\n",
    "for i in range(len(c_l)):\n",
    "    context_lengths.append(len(c_l[i].split()))\n",
    "\n",
    "for i in range(len(q_l)):\n",
    "    question_lengths.append(len(q_l[i].split()))\n",
    "\n",
    "for i in range(len(s_l)):\n",
    "    span_indxs.append(int(s_l[i].split()[1]))\n",
    "    \n",
    "print(\"Max question:\", max(question_lengths), \"MAx context:\", max(context_lengths), \"Max span:\", max(span_indxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(context_lengths)\n",
    "plt.title(\"Context Lengths distribution\")\n",
    "# plt.show()\n",
    "plt.hist(question_lengths)\n",
    "plt.title(\"Question Lengths distribution\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.hist(answer_lengths)\n",
    "# plt.title(\"Answer Lengths distribution\")\n",
    "# plt.show()\n",
    "del plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model the generator for the tensorflow model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "st = \"\"\"def generator(samples, session, batch_size = 32):\n",
    "    num_samples = len(samples)\n",
    "    \n",
    "    while 1:\n",
    "        sklearn.utils.shuffle(samples)\n",
    "        \n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "            labels = []\n",
    "            reviews_embeddings = []\n",
    "            \n",
    "            for batch_sample in batch_samples:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyRNNCell(tf.nn.rnn_cell.RNNCell):\n",
    "  \"\"\"The most basic RNN cell.\n",
    "  Args:\n",
    "    num_units: int, The number of units in the RNN cell.\n",
    "    activation: Nonlinearity to use.  Default: `tanh`.\n",
    "    reuse: (optional) Python boolean describing whether to reuse variables\n",
    "     in an existing scope.  If not `True`, and the existing scope already has\n",
    "     the given variables, an error is raised.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, num_units, activation=None, reuse=None):\n",
    "    super(MyRNNCell, self).__init__(_reuse=reuse)\n",
    "    self._num_units = num_units\n",
    "\n",
    "  @property\n",
    "  def state_size(self):\n",
    "    return self._num_units\n",
    "\n",
    "  @property\n",
    "  def output_size(self):\n",
    "    return self._num_units\n",
    "\n",
    "  def call(self, inputs, state):\n",
    "    \"\"\"Most basic RNN: output = new_state = act(W * input + U * state + B).\"\"\"\n",
    "    \n",
    "    # reshape vectors to matrices\n",
    "    state_prev = tf.reshape(state, [1, self.state_size])\n",
    "    x = tf.reshape(x, [1,state_size])\n",
    "    # initializer\n",
    "    xav_init = tf.contrib.layers.xavier_initializer\n",
    "    # params\n",
    "    Whh = tf.get_variable('Whh', shape=[hsize, hsize], initializer=xav_init())\n",
    "    Wih = tf.get_variable('Wih', shape=[state_size, hsize], initializer=xav_init())\n",
    "    b = tf.get_variable('b', shape=[hsize], initializer=tf.constant_initializer(0.001))\n",
    "    \n",
    "    \n",
    "    # current hidden state\n",
    "    h = tf.tanh(tf.matmul(hprev, W) + tf.matmul(x,U) + b)\n",
    "    h = tf.reshape(h, [hsize])\n",
    "\n",
    "    output = tf.tanh(tf.matmul(state, W_h) + tf.matmul(inputs, W_x) + b) #_linear([inputs, state], self._num_units, True))\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Question Module\n",
    "q_state_sz = 64\n",
    "\n",
    "def question_module(init_state=None):\n",
    "    '''\n",
    "    @arg init_state :tf.Tensor of shape (batch_size, q_state_sz)\n",
    "    \n",
    "    @return (op, state, c_batch) where op(output) and state are of shape (batch_size, q_state_sz)\n",
    "            and q_batch is the question_batched input placeholder\n",
    "    '''\n",
    "    q_batch = tf.placeholder(tf.float32, [Q_SIZE, batch_size, W2VEC_LEN])\n",
    "    seq_lens = tf.placeholder(tf.int32, [batch_size,])\n",
    "\n",
    "    #Define RNN Cell\n",
    "    q_cell = tf.nn.rnn_cell.BasicRNNCell(q_state_sz)\n",
    "    #LSTM version: Note that the state o/p of LSTM is different: It is a LSTMStateTuple:(cell, state)\n",
    "    #q_cell = tf.nn.rnn_cell.BasicLSTMCell(q_state_sz, forget_bias=1.0)\n",
    "    \n",
    "    #Default initial state is all zeros\n",
    "    outputs, state = tf.nn.dynamic_rnn(q_cell, q_batch,\n",
    "                                      initial_state=init_state,\n",
    "                                      dtype=tf.float32, time_major=True,\n",
    "                                      sequence_length=seq_lens)\n",
    "\n",
    "    return outputs, state, q_batch, seq_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Context Module\n",
    "c_state_sz = 64\n",
    "def context_module(init_state):\n",
    "    '''\n",
    "    @arg init_state :tf.Tensor of shape (batch_size, c_state_sz)\n",
    "\n",
    "    @return (op, state, c_batch) where op(output) and state are of shape (batch_size, c_state_sz)\n",
    "            and c_batch is the context_batched input placeholder\n",
    "    '''\n",
    "    if init_state is None: raise ValueError(\"Dnt Kid me!!. Give a state\")\n",
    "    c_batch = tf.placeholder(tf.float32, [C_SIZE, batch_size, W2VEC_LEN])\n",
    "    seq_lens = tf.placeholder(tf.int32, [batch_size,])\n",
    "    \n",
    "    context_cell = tf.nn.rnn_cell.BasicRNNCell(c_state_sz)\n",
    "    #LSTM version: Note that the state o/p of LSTM is different: It is a LSTMStateTuple:(cell, state)\n",
    "    #context_cell = tf.nn.rnn_cell.BasicLSTMCell(c_state_sz, forget_bias=1.0)\n",
    "\n",
    "#     outputs, state = tf.nn.static_rnn(context_cell, x,\n",
    "#                                        initial_state=init_state,\n",
    "#                                        dtype=tf.float32)\n",
    "    outputs, state = tf.nn.dynamic_rnn(context_cell, c_batch,\n",
    "                                  initial_state=init_state,\n",
    "                                  dtype=tf.float32, time_major=True,\n",
    "                                  sequence_length=seq_lens)\n",
    "\n",
    "\n",
    "    return outputs, state, c_batch, seq_lens\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Answer Module\n",
    "def _init_wts(shape):\n",
    "    bound = np.sqrt(6.0 / sum(shape))\n",
    "    wts = tf.random_uniform(shape, minval=-bound, maxval=bound, dtype=tf.float32)\n",
    "    #wts = tf.random_normal(shape, stddev=np.sqrt(2.0 / np.sum(shape)), dtype=tf.float64)\n",
    "    return tf.Variable(wts)\n",
    "\n",
    "def _init_bias(sz):\n",
    "    b = np.ones(sz)*0.001\n",
    "    return tf.Variable(b, dtype=tf.float32)\n",
    "\n",
    "def answer_module(ip_state, layers=[1024, 256]):\n",
    "    '''\n",
    "    ip_state: tf.Tensor of shape (batch_sz, C_SIZE)\n",
    "    layers: List of hidden_layer sizes to be used\n",
    "    \n",
    "    @return: tf.Tensor variables of loss gradient and loss and labes placeholder\n",
    "    '''\n",
    "    prev_feature_sz = c_state_sz\n",
    "    conditioned_state =  ip_state  #State(Context|Question)\n",
    "\n",
    "    X = conditioned_state\n",
    "    \n",
    "    for layer in layers:\n",
    "        w = _init_wts((prev_feature_sz, layer))\n",
    "        b = _init_bias(layer)\n",
    "        prev_feature_sz = layer\n",
    "        h_l = tf.nn.relu(tf.matmul(X, w) + b)\n",
    "        X = h_l\n",
    "    \n",
    "    #Final O/P layer\n",
    "    w_s = _init_wts((prev_feature_sz, C_SIZE)); b_s = _init_bias(C_SIZE)\n",
    "    w_e = _init_wts((prev_feature_sz, C_SIZE)); b_e = _init_bias(C_SIZE)\n",
    "    \n",
    "    logits_s = tf.matmul(X, w_s) + b_s\n",
    "    logits_e = tf.matmul(X, w_e) + b_e\n",
    "\n",
    "    return logits_s, logits_e\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_fn(logits_s, logits_e):\n",
    "    labels_holder = tf.placeholder(tf.float32, shape=(2, batch_size, C_SIZE))\n",
    "    loss_s = tf.nn.softmax_cross_entropy_with_logits(logits=logits_s, labels=labels_holder[0,:])\n",
    "    loss_e  = tf.nn.softmax_cross_entropy_with_logits(logits=logits_e, labels=labels_holder[1,:])\n",
    "    \n",
    "    probs_s = tf.nn.softmax(logits_s)\n",
    "    probs_e = tf.nn.softmax(logits_e)\n",
    "    preds_s = tf.argmax(probs_s, axis=1)\n",
    "    preds_e = tf.argmax(probs_e, axis=1)\n",
    "    \n",
    "    loss_s_mean = tf.reduce_mean(loss_s)\n",
    "    loss_e_mean  = tf.reduce_mean(loss_e)\n",
    "    loss = tf.add(loss_s_mean, loss_e_mean)\n",
    "    \n",
    "    #optimizer = tf.train.GradientDescentOptimizer(learning_rate = 1e-5).minimize(loss)\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    loss_grad = optimizer.minimize(loss)  #Gradient Clipping is part of it    \n",
    "    \n",
    "    return loss_grad, loss, labels_holder, preds_s, preds_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#BUILD the Computational graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.variable_scope(\"question_module\"):\n",
    "    q_ops, q_state, q_batch_ip, q_seq_lens_holder = question_module(None)\n",
    "with tf.variable_scope(\"context_module\"):\n",
    "    c_ops, c_state, c_batch_ip, c_seq_lens_holder = context_module(q_state)\n",
    "with tf.variable_scope(\"answer_module\"):\n",
    "    logits_s, logits_e = answer_module(c_state)\n",
    "with tf.variable_scope(\"loss_module\"):\n",
    "    loss_grad_train, loss_train, labels_ip_train, preds_s, preds_e = loss_fn(logits_s, logits_e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate a random sample and get metrics\n",
    "def get_metrics(dataset, sess=None, sample=100):\n",
    "    '''\n",
    "    @param dataset: tuple of (List of questions, List of contexts, List of spans)\n",
    "    '''\n",
    "    q_l, c_l, s_l = dataset\n",
    "    \n",
    "    #Placeholders to be filled: q_batch_ip, q_seq_lens_holder, c_seq_lens_holder, c_batch_ip, labels_ip_train\n",
    "    \n",
    "    if sess == None: \n",
    "        sess = tf.Session()\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        \n",
    "    (q_vecs, q_lens), (c_vecs, c_lens), label_vecs, idx = get_batch(cnt=batch_size)\n",
    "    \n",
    "    q_vecs_ip = q_vecs.transpose(1,0,2) #To make it to (time_steps, batch_size, word_vec_len_features) shape\n",
    "    c_vecs_ip = c_vecs.transpose(1,0,2) #To make it to (time_steps, batch_size, word_vec_len_features) shape\n",
    "    label_vecs = label_vecs.reshape(2, batch_size, C_SIZE)\n",
    "    \n",
    "    start, end = sess.run([preds_s, preds_e], feed_dict={q_batch_ip : q_vecs_ip,\n",
    "                                              q_seq_lens_holder : q_lens,\n",
    "                                              c_seq_lens_holder : c_lens,\n",
    "                                              c_batch_ip : c_vecs_ip,\n",
    "                                              labels_ip_train: label_vecs})\n",
    "    \n",
    "    em_scr = 0; f1_scr = 0\n",
    "    for _id, (s, e) in enumerate(zip(start, end)):\n",
    "        pred_ans_sent = get_answer_txt(s, e, c_l[_id])\n",
    "        gs, ge = map(int, s_l[_id].split())\n",
    "        ground_truth  = get_answer_txt(gs, ge, c_l[_id])\n",
    "        em_scr += exact_match_score(pred_ans_sent, ground_truth)\n",
    "        f1_scr += f1_score(pred_ans_sent, ground_truth)\n",
    "    \n",
    "    return em_scr, f1_scr\n",
    "        \n",
    "# get_metrics((q_l, c_l, s_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "0  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  \n",
      "Itr: 20, Loss:12.4499, Acc:0.157894736842, Time:7.81588602066\n",
      "20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  \n",
      "Itr: 40, Loss:12.408, Acc:1.39737332515, Time:8.11112999916\n",
      "40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  \n",
      "Itr: 60, Loss:12.4458, Acc:1.2320952992, Time:8.10874700546\n",
      "60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  \n",
      "Itr: 80, Loss:12.423, Acc:0.163059163059, Time:8.13810110092\n",
      "80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99  \n",
      "Itr: 100, Loss:12.4503, Acc:0.420779220779, Time:8.08291888237\n",
      "100  101  102  103  104  105  106  107  108  109  110  111  112  113  114  115  116  117  118  119  \n",
      "Itr: 120, Loss:12.4296, Acc:1.05612230708, Time:8.13833093643\n",
      "120  121  122  123  124  125  126  127  128  129  130  131  132  133  134  135  136  137  138  139  \n",
      "Itr: 140, Loss:12.4346, Acc:0.317154875294, Time:8.2939081192\n",
      "140  141  142  143  144  145  146  147  148  149  150  151  152  153  154  155  156  157  158  159  \n",
      "Itr: 160, Loss:12.4233, Acc:0.199786704586, Time:8.07843494415\n",
      "160  161  162  163  164  165  166  167  168  169  170  171  172  173  174  175  176  177  178  179  \n",
      "Itr: 180, Loss:12.4279, Acc:0.0173913043478, Time:8.07451200485\n",
      "180  181  182  183  184  185  186  187  188  189  190  191  192  193  194  195  196  197  198  199  \n",
      "Itr: 200, Loss:12.4081, Acc:0.858788532221, Time:8.09258794785\n",
      "200  201  202  203  204  205  206  207  208  209  210  211  212  213  214  215  216  217  218  219  \n",
      "Itr: 220, Loss:12.4374, Acc:0.0298507462687, Time:8.04171800613\n",
      "220  221  222  223  224  225  226  227  228  229  230  231  232  233  234  235  236  237  238  239  \n",
      "Itr: 240, Loss:12.4418, Acc:0.222222222222, Time:8.08163404465\n",
      "240  241  242  243  244  245  246  247  248  249  250  251  252  253  254  255  256  257  258  259  \n",
      "Itr: 260, Loss:12.4388, Acc:0.545414649624, Time:8.09142303467\n",
      "260  261  262  263  264  265  266  267  268  269  270  271  272  273  274  275  276  277  278  279  \n",
      "Itr: 280, Loss:12.4382, Acc:0, Time:8.00682401657\n",
      "280  281  282  283  284  285  286  287  288  289  290  291  292  293  294  295  296  297  298  299  \n",
      "Itr: 300, Loss:12.4574, Acc:0.39726338178, Time:8.22323608398\n",
      "300  301  302  303  304  305  306  307  308  309  310  311  312  313  314  315  316  317  318  319  \n",
      "Itr: 320, Loss:12.4546, Acc:0.330688139417, Time:8.33404397964\n",
      "320  321  322  323  324  325  326  327  328  329  330  331  332  333  334  335  336  337  338  339  \n",
      "Itr: 340, Loss:12.4369, Acc:0.467262955624, Time:8.48563289642\n",
      "340  341  342  343  344  345  346  347  348  349  350  351  352  353  354  355  356  357  358  359  \n",
      "Itr: 360, Loss:12.4235, Acc:0.706838464207, Time:8.19975209236\n",
      "360  361  362  363  364  365  366  367  368  369  370  371  372  373  374  375  376  377  378  379  \n",
      "Itr: 380, Loss:12.4709, Acc:0.0952853598015, Time:8.27936792374\n",
      "380  381  382  383  384  385  386  387  388  389  390  391  392  393  394  395  396  397  398  399  \n",
      "Itr: 400, Loss:12.3949, Acc:0.677322880372, Time:8.4068069458\n",
      "400  401  402  403  404  405  406  407  408  409  410  411  412  413  414  415  416  417  418  419  \n",
      "Itr: 420, Loss:12.4476, Acc:1.16968076451, Time:8.2540140152\n",
      "420  421  422  423  424  425  426  427  428  429  430  431  432  433  434  435  436  437  438  439  \n",
      "Itr: 440, Loss:12.4209, Acc:0.84301912974, Time:8.32303404808\n",
      "440  441  442  443  444  445  446  447  448  449  450  451  452  453  454  455  456  457  458  459  \n",
      "Itr: 460, Loss:12.4303, Acc:0.624060150376, Time:8.0085709095\n",
      "460  461  462  463  464  465  466  467  468  469  470  471  472  473  474  475  476  477  478  479  \n",
      "Itr: 480, Loss:12.4285, Acc:0.544447446906, Time:8.03313302994\n",
      "480  481  482  483  484  485  486  487  488  489  490  491  492  493  494  495  496  497  498  499  \n",
      "Itr: 500, Loss:12.4335, Acc:0.173913043478, Time:8.28458094597\n",
      "500  501  502  503  504  505  506  507  508  509  510  511  512  513  514  515  516  517  518  519  \n",
      "Itr: 520, Loss:12.4476, Acc:0, Time:8.03221321106\n",
      "520  521  522  523  524  525  526  527  528  529  530  531  532  533  534  535  536  537  538  539  \n",
      "Itr: 540, Loss:12.4498, Acc:0.808048242889, Time:8.02014684677\n",
      "540  541  542  543  544  545  546  547  548  549  550  551  552  553  554  555  556  557  558  559  \n",
      "Itr: 560, Loss:12.4281, Acc:0.446832115253, Time:8.01340007782\n",
      "560  561  562  563  564  565  566  567  568  "
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-bd9cefa36aa0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-34-bd9cefa36aa0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0mq_vecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_lens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mc_vecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_lens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_vecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mq_vecs_ip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq_vecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#To make it to (time_steps, batch_size, word_vec_len_features) shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mc_vecs_ip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_vecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#To make it to (time_steps, batch_size, word_vec_len_features) shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-6ac975030bf2>\u001b[0m in \u001b[0;36mget_batch\u001b[0;34m(cnt, filtr)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m#vecorize(c_l[idx], fill=C_SIZE).reshape((1, C_SIZE, W2VEC_LEN))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m#c_vecs = np.concatenate((c_vecs, c_vec), axis=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mspan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_l\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspan\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mC_SIZE\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfiltr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "import time\n",
    "\n",
    "def train():\n",
    "    N = (len(q_l) if DATA_CAP is None else DATA_CAP)\n",
    "    itr = 0\n",
    "    \n",
    "    for _ in range(num_epochs):\n",
    "        print(\"Epoch: \", _)\n",
    "        st = time.time()\n",
    "        for batches in np.arange(N/batch_size):\n",
    "            print(batches,\" \", end=\"\")\n",
    "\n",
    "            (q_vecs, q_lens), (c_vecs, c_lens), label_vecs, _ = get_batch(cnt=batch_size)\n",
    "            q_vecs_ip = q_vecs.transpose(1,0,2) #To make it to (time_steps, batch_size, word_vec_len_features) shape\n",
    "            c_vecs_ip = c_vecs.transpose(1,0,2) #To make it to (time_steps, batch_size, word_vec_len_features) shape\n",
    "            label_vecs = label_vecs.reshape(2, batch_size, C_SIZE)\n",
    "#             print(sess.run(c_state, feed_dict={q_batch_ip : q_vecs_ip,\n",
    "#                                                c_batch_ip : c_vecs_ip}))\n",
    "#             sess.run(q_state, feed_dict={q_batch_ip : q_vecs_ip,\n",
    "#                                            c_batch_ip : c_vecs_ip,\n",
    "#                                            labels_ip_train : label_vecs})\n",
    "            \n",
    "            ret = sess.run(loss_train, feed_dict={q_batch_ip : q_vecs_ip,\n",
    "                                                  q_seq_lens_holder : q_lens,\n",
    "                                                  c_seq_lens_holder : c_lens,\n",
    "                                                  c_batch_ip : c_vecs_ip,\n",
    "                                                  labels_ip_train : label_vecs})\n",
    "            itr += 1\n",
    "            if itr % 20 == 0:\n",
    "                end = time.time()\n",
    "                loss = sess.run(loss_train, feed_dict={q_batch_ip : q_vecs_ip,\n",
    "                                                       q_seq_lens_holder : q_lens, \n",
    "                                                       c_seq_lens_holder : c_lens,\n",
    "                                                       c_batch_ip : c_vecs_ip,\n",
    "                                                       labels_ip_train : label_vecs})\n",
    "                em, f1 = get_metrics((q_l, c_l, s_l))\n",
    "                print(\"\\nItr: %s, Loss:%s, Acc:%s, Time:%s\"%(itr, loss, f1, end-st))\n",
    "                st = end\n",
    "\n",
    "#tf.reset_default_graph()\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
