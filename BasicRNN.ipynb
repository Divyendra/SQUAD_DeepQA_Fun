{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQUAD Question Answering Dataset - Basic RNN\n",
    "SQUAD - Stanford Question Answering Dataset is a new reading comprehension dataset. It consists of questions posed by crowd workers on a set of wikipedia articles where the answer to every question is a segment o text, or span, from the corresponding reading passage. There are 1,00,000+ question answer pairs on 500+ articles. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formal definition of the SQUAD Question answering dataset\n",
    "1. Given a three tuple (Q,P,($a_{s},a_{e}$)), where Q is the question, P is the context paragraph and $a_{s}$ and $a_{e}$ are the start and end indices. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process\n",
    "1. Both the question and the context vectors are first encoded into a LSTM. \n",
    "2. Word embeddings are passed onto the encoder that generated an attention vector which the decoder decodes to produce the final output. \n",
    "3. Can use 100 dimensional glove embeddings. \n",
    "4. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function for the SQUAD Model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "1. Dataset importing from JSON format\n",
    "2. Extracting data.\n",
    "3. Downloading the Glove Vector model for the Word 2 vectors. Try with the 50 length vector first and then increase that. \n",
    "4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from utils import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "Q_SIZE = 40  #Upper bound of max question size\n",
    "C_SIZE = 500 #Upper bound of max context size\n",
    "\n",
    "## RNN Model Parameters\n",
    "DATA_CAP = None\n",
    "batch_size = 64\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Glove vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "W2VEC_LEN = 50\n",
    "GLOVE_path = \"./preprocessing/data/glove.6B/glove.6B.50d.txt\"\n",
    "reader = csv.reader(open(GLOVE_path), delimiter=' ', quoting=csv.QUOTE_NONE) \n",
    "W2VEC = {line[0]: np.array(list(map(float, line[1: ]))) for line in reader}\n",
    "del csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize(sent, fill, clean=False):\n",
    "    \"\"\"Takes a sentence and returns corresponing list of GloVecs\n",
    "    @return (ndarray of glovecs, actual_length)\n",
    "    \"\"\"\n",
    "    if clean:\n",
    "        pass #sent = _dataCleaning(sent)\n",
    "    words = sent.split(\" \")\n",
    "    words = words[:fill]  #Capping the context. Beware!!\n",
    "    vecs = np.empty((1,W2VEC_LEN))\n",
    "    for w in words:\n",
    "        vec = W2VEC.get(w.lower(), None)\n",
    "        if vec is None:\n",
    "            vec = np.random.rand(W2VEC_LEN)\n",
    "        vec = vec.reshape((1,W2VEC_LEN))\n",
    "        vecs = np.concatenate((vecs, vec), axis=0)\n",
    "    \n",
    "    PADDING = np.zeros((1, W2VEC_LEN))\n",
    "    for _ in np.arange(fill - len(words)):\n",
    "        vecs = np.concatenate((vecs, PADDING), axis=0)\n",
    "    return vecs[1:], len(words)\n",
    "\n",
    "def _dataCleaning(string):\n",
    "    strip_special_chars = re.compile(\"[^A-Za-z0-9 ]+\")\n",
    "    string = string.replace(\"<br />\", \" \")\n",
    "    string = string.replace(\"''\", '\" ')\n",
    "    string = string.replace(\"``\", '\" ')\n",
    "    return re.sub(strip_special_chars, \"\", string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset for questions and answers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Entries#:All should be same: 81403 81403 81403 81403\n"
     ]
    }
   ],
   "source": [
    "## Loading the dataset here. \n",
    "from itertools import izip\n",
    "path = \"./preprocessing/data/squad/\"\n",
    "#Paths\n",
    "q_p = \"train.question\"; c_p = \"train.context\"; s_p = \"train.span\"\n",
    "#Lines\n",
    "q_l = []; c_l = []; s_l = []\n",
    "\n",
    "itr = 0\n",
    "with open(path+q_p) as q_f, \\\n",
    "     open(path+c_p) as c_f, \\\n",
    "     open(path+s_p) as s_f:\n",
    "    for q, c, s in izip(q_f, c_f, s_f):\n",
    "        c = _dataCleaning(c)\n",
    "        q_l.append(q), c_l.append(c); s_l.append(s)\n",
    "        itr += 1\n",
    "\n",
    "print(\"#Entries#:All should be same:\", itr, len(q_l), len(c_l), len(s_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Vectorise all Questions and Contexts\n",
    "def get_batch(cnt=64, filtr=True):\n",
    "    \"\"\"\n",
    "    @param filtr: Filters only entries with context less than C_SIZE\n",
    "    \n",
    "    Returns Batch of 'cnt' elements from the dataset as vectorized numpy arrays\n",
    "    @return: (questions, answers, labels, ids) : The first three being numpy vectorised arrays.\n",
    "                                                'ids' is a list of corresponding entry ids in q_l,c_l,s_l\n",
    "                                                questions shape would be (cnt, Q_SIZE, W2VEC_LEN)\n",
    "    Each entry of labels is a one-hot repr of span given\n",
    "    \n",
    "    The numpy concatenate function copies at every call and hence is 10X slower for large batches.\n",
    "    Traditional Python lists append is a better fit here.\n",
    "    \"\"\"\n",
    "    N = (len(q_l) if DATA_CAP is None else DATA_CAP)\n",
    "    batch_ids = list(np.random.randint(0, N, cnt))\n",
    "    rmv_ids = []\n",
    "    q_vecs = []; c_vecs = []; label_vecs = []; q_lens = []; c_lens = []\n",
    "\n",
    "    #q_vecs = np.empty((1, Q_SIZE, W2VEC_LEN)); c_vecs = np.empty((1, C_SIZE, W2VEC_LEN))\n",
    "    for idx in batch_ids:\n",
    "        #q_vec = vectorize(q_l[idx], fill=Q_SIZE).reshape((1, Q_SIZE, W2VEC_LEN))\n",
    "        #q_vecs = np.concatenate((q_vecs, q_vec), axis=0)\n",
    "        #c_vec = vecty\n",
    "        #vecorize(c_l[idx], fill=C_SIZE).reshape((1, C_SIZE, W2VEC_LEN))\n",
    "        #c_vecs = np.concatenate((c_vecs, c_vec), axis=0)\n",
    "        span = map(int, s_l[idx].split())\n",
    "        try:\n",
    "            if span[1] >= C_SIZE and filtr:\n",
    "                replacement = np.random.randint(0, N, 1)[0]\n",
    "                rmv_ids.append(idx)\n",
    "                batch_ids.append(replacement)\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            print(e, \"id:\", idx)\n",
    "            continue\n",
    "        q_vec, q_actual_len = vectorize(q_l[idx], fill=Q_SIZE)\n",
    "        q_vecs.append(q_vec); q_lens.append(q_actual_len)\n",
    "        c_vec, c_actual_len = vectorize(c_l[idx], fill=C_SIZE, clean=True)\n",
    "        c_vecs.append(c_vec); c_lens.append(c_actual_len)\n",
    "        \n",
    "        label_vec = np.zeros(2*C_SIZE) #start_end_vec + end_span_vec\n",
    "        idx = [span[0], C_SIZE + span[1]]\n",
    "        label_vec[idx] = 1\n",
    "        label_vecs.append(label_vec)\n",
    "\n",
    "    q_vecs = np.array(q_vecs); c_vecs = np.array(c_vecs); label_vecs = np.array(label_vecs)\n",
    "    q_lens = np.array(q_lens); c_lens = np.array(c_lens)\n",
    "    \n",
    "    batch_ids = set(batch_ids); rmv_ids = set(rmv_ids)\n",
    "    final_ids = batch_ids.difference(rmv_ids)\n",
    "    return (q_vecs, q_lens), (c_vecs, c_lens), label_vecs, final_ids\n",
    "    #print(q_vecs.shape, c_vecs.shape, label_vecs.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max question: 60 MAx context: 655 Max span: 605\n"
     ]
    }
   ],
   "source": [
    "context_lengths = []\n",
    "question_lengths = []\n",
    "span_indxs = []\n",
    "\n",
    "for i in range(len(c_l)):\n",
    "    context_lengths.append(len(c_l[i].split()))\n",
    "\n",
    "for i in range(len(q_l)):\n",
    "    question_lengths.append(len(q_l[i].split()))\n",
    "\n",
    "for i in range(len(s_l)):\n",
    "    span_indxs.append(int(s_l[i].split()[1]))\n",
    "    \n",
    "print(\"Max question:\", max(question_lengths), \"MAx context:\", max(context_lengths), \"Max span:\", max(span_indxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(context_lengths)\n",
    "plt.title(\"Context Lengths distribution\")\n",
    "# plt.show()\n",
    "plt.hist(question_lengths)\n",
    "plt.title(\"Question Lengths distribution\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.hist(answer_lengths)\n",
    "# plt.title(\"Answer Lengths distribution\")\n",
    "# plt.show()\n",
    "del plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model the generator for the tensorflow model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "st = \"\"\"def generator(samples, session, batch_size = 32):\n",
    "    num_samples = len(samples)\n",
    "    \n",
    "    while 1:\n",
    "        sklearn.utils.shuffle(samples)\n",
    "        \n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "            labels = []\n",
    "            reviews_embeddings = []\n",
    "            \n",
    "            for batch_sample in batch_samples:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyRNNCell(tf.nn.rnn_cell.RNNCell):\n",
    "  \"\"\"The most basic RNN cell.\n",
    "  Args:\n",
    "    num_units: int, The number of units in the RNN cell.\n",
    "    activation: Nonlinearity to use.  Default: `tanh`.\n",
    "    reuse: (optional) Python boolean describing whether to reuse variables\n",
    "     in an existing scope.  If not `True`, and the existing scope already has\n",
    "     the given variables, an error is raised.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, num_units, activation=None, reuse=None):\n",
    "    super(MyRNNCell, self).__init__(_reuse=reuse)\n",
    "    self._num_units = num_units\n",
    "\n",
    "  @property\n",
    "  def state_size(self):\n",
    "    return self._num_units\n",
    "\n",
    "  @property\n",
    "  def output_size(self):\n",
    "    return self._num_units\n",
    "\n",
    "  def call(self, inputs, state):\n",
    "    \"\"\"Most basic RNN: output = new_state = act(W * input + U * state + B).\"\"\"\n",
    "    \n",
    "    # reshape vectors to matrices\n",
    "    state_prev = tf.reshape(state, [1, self.state_size])\n",
    "    x = tf.reshape(x, [1,state_size])\n",
    "    # initializer\n",
    "    xav_init = tf.contrib.layers.xavier_initializer\n",
    "    # params\n",
    "    Whh = tf.get_variable('Whh', shape=[hsize, hsize], initializer=xav_init())\n",
    "    Wih = tf.get_variable('Wih', shape=[state_size, hsize], initializer=xav_init())\n",
    "    b = tf.get_variable('b', shape=[hsize], initializer=tf.constant_initializer(0.001))\n",
    "    \n",
    "    \n",
    "    # current hidden state\n",
    "    h = tf.tanh(tf.matmul(hprev, W) + tf.matmul(x,U) + b)\n",
    "    h = tf.reshape(h, [hsize])\n",
    "\n",
    "    output = tf.tanh(tf.matmul(state, W_h) + tf.matmul(inputs, W_x) + b) #_linear([inputs, state], self._num_units, True))\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Question Module\n",
    "q_state_sz = 64\n",
    "\n",
    "def question_module(init_state=None):\n",
    "    '''\n",
    "    @arg init_state :tf.Tensor of shape (batch_size, q_state_sz)\n",
    "    \n",
    "    @return (op, state, c_batch) where op(output) and state are of shape (batch_size, q_state_sz)\n",
    "            and q_batch is the question_batched input placeholder\n",
    "    '''\n",
    "    q_batch = tf.placeholder(tf.float32, [Q_SIZE, batch_size, W2VEC_LEN])\n",
    "    seq_lens = tf.placeholder(tf.int32, [batch_size,])\n",
    "\n",
    "    #Define RNN Cell\n",
    "    q_cell = tf.nn.rnn_cell.BasicRNNCell(q_state_sz)\n",
    "    #LSTM version: Note that the state o/p of LSTM is different: It is a LSTMStateTuple:(cell, state)\n",
    "    #q_cell = tf.nn.rnn_cell.BasicLSTMCell(q_state_sz, forget_bias=1.0)\n",
    "    \n",
    "    #Default initial state is all zeros\n",
    "    outputs, state = tf.nn.dynamic_rnn(q_cell, q_batch,\n",
    "                                      initial_state=init_state,\n",
    "                                      dtype=tf.float32, time_major=True,\n",
    "                                      sequence_length=seq_lens)\n",
    "\n",
    "    return outputs, state, q_batch, seq_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Context Module\n",
    "c_state_sz = 64\n",
    "def context_module(init_state):\n",
    "    '''\n",
    "    @arg init_state :tf.Tensor of shape (batch_size, c_state_sz)\n",
    "\n",
    "    @return (op, state, c_batch) where op(output) and state are of shape (batch_size, c_state_sz)\n",
    "            and c_batch is the context_batched input placeholder\n",
    "    '''\n",
    "    if init_state is None: raise ValueError(\"Dnt Kid me!!. Give a state\")\n",
    "    c_batch = tf.placeholder(tf.float32, [C_SIZE, batch_size, W2VEC_LEN])\n",
    "    seq_lens = tf.placeholder(tf.int32, [batch_size,])\n",
    "    \n",
    "    context_cell = tf.nn.rnn_cell.BasicRNNCell(c_state_sz)\n",
    "    #LSTM version: Note that the state o/p of LSTM is different: It is a LSTMStateTuple:(cell, state)\n",
    "    #context_cell = tf.nn.rnn_cell.BasicLSTMCell(c_state_sz, forget_bias=1.0)\n",
    "\n",
    "#     outputs, state = tf.nn.static_rnn(context_cell, x,\n",
    "#                                        initial_state=init_state,\n",
    "#                                        dtype=tf.float32)\n",
    "    outputs, state = tf.nn.dynamic_rnn(context_cell, c_batch,\n",
    "                                  initial_state=init_state,\n",
    "                                  dtype=tf.float32, time_major=True,\n",
    "                                  sequence_length=seq_lens)\n",
    "\n",
    "\n",
    "    return outputs, state, c_batch, seq_lens\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Answer Module\n",
    "def _init_wts(shape):\n",
    "    bound = np.sqrt(6.0 / sum(shape))\n",
    "    wts = tf.random_uniform(shape, minval=-bound, maxval=bound, dtype=tf.float32)\n",
    "    #wts = tf.random_normal(shape, stddev=np.sqrt(2.0 / np.sum(shape)), dtype=tf.float64)\n",
    "    return tf.Variable(wts)\n",
    "\n",
    "def _init_bias(sz):\n",
    "    b = np.ones(sz)*0.001\n",
    "    return tf.Variable(b, dtype=tf.float32)\n",
    "\n",
    "def answer_module(ip_state, layers=[]):\n",
    "    '''\n",
    "    ip_state: tf.Tensor of shape (batch_sz, C_SIZE)\n",
    "    layers: List of hidden_layer sizes to be used\n",
    "    \n",
    "    @return: tf.Tensor variables of loss gradient and loss and labes placeholder\n",
    "    '''\n",
    "    prev_feature_sz = c_state_sz\n",
    "    conditioned_state =  ip_state  #State(Context|Question)\n",
    "\n",
    "    X = conditioned_state\n",
    "    \n",
    "    for layer in layers:\n",
    "        w = _init_wts((prev_feature_sz, layer))\n",
    "        b = _init_bias(layer)\n",
    "        prev_feature_sz = layer\n",
    "        h_l = tf.nn.relu(tf.matmul(X, w) + b)\n",
    "        X = h_l\n",
    "    \n",
    "    #Final O/P layer\n",
    "    w_s = _init_wts((prev_feature_sz, C_SIZE)); b_s = _init_bias(C_SIZE)\n",
    "    w_e = _init_wts((prev_feature_sz, C_SIZE)); b_e = _init_bias(C_SIZE)\n",
    "    \n",
    "    logits_s = tf.matmul(X, w_s) + b_s\n",
    "    logits_e = tf.matmul(X, w_e) + b_e\n",
    "\n",
    "    return logits_s, logits_e\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_fn(logits_s, logits_e):\n",
    "    labels_holder = tf.placeholder(tf.float32, shape=(2, batch_size, C_SIZE))\n",
    "    loss_s = tf.nn.softmax_cross_entropy_with_logits(logits=logits_s, labels=labels_holder[0,:])\n",
    "    loss_e  = tf.nn.softmax_cross_entropy_with_logits(logits=logits_e, labels=labels_holder[1,:])\n",
    "    \n",
    "    probs_s = tf.nn.softmax(logits_s)\n",
    "    probs_e = tf.nn.softmax(logits_e)\n",
    "    preds_s = tf.argmax(probs_s, axis=1)\n",
    "    preds_e = tf.argmax(probs_e, axis=1)\n",
    "    \n",
    "    loss_s_mean = tf.reduce_mean(loss_s)\n",
    "    loss_e_mean  = tf.reduce_mean(loss_e)\n",
    "    loss = tf.add(loss_s_mean, loss_e_mean)\n",
    "    \n",
    "    #optimizer = tf.train.GradientDescentOptimizer(learning_rate = 1e-5).minimize(loss)\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    loss_grad = optimizer.minimize(loss)  #Gradient Clipping is part of it    \n",
    "    \n",
    "    return loss_grad, loss, labels_holder, preds_s, preds_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#BUILD the Computational graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.variable_scope(\"question_module\"):\n",
    "    q_ops, q_state, q_batch_ip, q_seq_lens_holder = question_module(None)\n",
    "with tf.variable_scope(\"context_module\"):\n",
    "    c_ops, c_state, c_batch_ip, c_seq_lens_holder = context_module(q_state)\n",
    "with tf.variable_scope(\"answer_module\"):\n",
    "    logits_s, logits_e = answer_module(c_state)\n",
    "with tf.variable_scope(\"loss_module\"):\n",
    "    loss_grad_train, loss_train, labels_ip_train, preds_s, preds_e = loss_fn(logits_s, logits_e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate a random sample and get metrics\n",
    "def get_metrics(dataset, sess=None, sample=100):\n",
    "    '''\n",
    "    @param dataset: tuple of (List of questions, List of contexts, List of spans)\n",
    "    '''\n",
    "    q_l, c_l, s_l = dataset\n",
    "    \n",
    "    #Placeholders to be filled: q_batch_ip, q_seq_lens_holder, c_seq_lens_holder, c_batch_ip, labels_ip_train\n",
    "    \n",
    "    if sess == None: \n",
    "        sess = tf.Session()\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        \n",
    "    (q_vecs, q_lens), (c_vecs, c_lens), label_vecs, idx = get_batch(cnt=batch_size)\n",
    "    \n",
    "    q_vecs_ip = q_vecs.transpose(1,0,2) #To make it to (time_steps, batch_size, word_vec_len_features) shape\n",
    "    c_vecs_ip = c_vecs.transpose(1,0,2) #To make it to (time_steps, batch_size, word_vec_len_features) shape\n",
    "    label_vecs = label_vecs.reshape(2, batch_size, C_SIZE)\n",
    "    \n",
    "    start, end = sess.run([preds_s, preds_e], feed_dict={q_batch_ip : q_vecs_ip,\n",
    "                                              q_seq_lens_holder : q_lens,\n",
    "                                              c_seq_lens_holder : c_lens,\n",
    "                                              c_batch_ip : c_vecs_ip,\n",
    "                                              labels_ip_train: label_vecs})\n",
    "    \n",
    "    em_scr = 0; f1_scr = 0\n",
    "    common_len = 0; pred_len = 0; grnd_len = 0\n",
    "    for _id, (s, e) in enumerate(zip(start, end)):\n",
    "        pred_ans_sent = get_answer_txt(s, e, c_l[_id])\n",
    "        gs, ge = map(int, s_l[_id].split())\n",
    "        ground_truth  = get_answer_txt(gs, ge, c_l[_id])\n",
    "        common_l, pred_l, grnd_l = count_tokens(pred_ans_sent, ground_truth)\n",
    "        common_len += common_l; pred_len += pred_l; grnd_len += grnd_l\n",
    "        em_scr += exact_match_score(pred_ans_sent, ground_truth)\n",
    "        \n",
    "    f1_scr += f1_score(common_len, pred_len, grnd_len)\n",
    "    \n",
    "    return em_scr, f1_scr\n",
    "        \n",
    "# get_metrics((q_l, c_l, s_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "0  1  2  3  4  \n",
      "Itr: 5, Loss:12.4473, Acc:0.0320134793597, Time:2.02008700371\n",
      "5  6  7  8  9  \n",
      "Itr: 10, Loss:12.4301, Acc:0.0218265364733, Time:2.55919694901\n",
      "10  11  12  13  14  \n",
      "Itr: 15, Loss:12.4505, Acc:0.0507936507937, Time:2.6016600132\n",
      "15  16  17  18  19  \n",
      "Itr: 20, Loss:12.4235, Acc:0.0394618834081, Time:2.574696064\n",
      "20  21  22  23  24  \n",
      "Itr: 25, Loss:12.4117, Acc:0.0172626387176, Time:2.47731184959\n",
      "25  26  27  28  29  \n",
      "Itr: 30, Loss:12.4507, Acc:0.0170575692964, Time:2.48838019371\n",
      "30  31  32  33  34  \n",
      "Itr: 35, Loss:12.4342, Acc:0.0339805825243, Time:2.62697100639\n",
      "35  36  37  38  39  \n",
      "Itr: 40, Loss:12.4571, Acc:0.00308166409861, Time:2.49612283707\n",
      "40  41  42  43  44  \n",
      "Itr: 45, Loss:12.4266, Acc:0.0471894517696, Time:2.48649501801\n",
      "45  46  47  48  49  \n",
      "Itr: 50, Loss:12.4423, Acc:0.0575539568345, Time:2.49991607666\n",
      "50  51  52  53  54  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-2615cf58f823>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-59-2615cf58f823>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m                                                        \u001b[0mc_batch_ip\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mc_vecs_ip\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                                                        labels_ip_train : label_vecs})\n\u001b[0;32m---> 37\u001b[0;31m                 \u001b[0mem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_l\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                 \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nItr: %s, Loss:%s, Acc:%s, Time:%s\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-58-c3626bbe7e13>\u001b[0m in \u001b[0;36mget_metrics\u001b[0;34m(dataset, sess, sample)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mq_vecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_lens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mc_vecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_lens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_vecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mq_vecs_ip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq_vecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#To make it to (time_steps, batch_size, word_vec_len_features) shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-6ac975030bf2>\u001b[0m in \u001b[0;36mget_batch\u001b[0;34m(cnt, filtr)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mq_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_actual_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_l\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mQ_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mq_vecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mq_lens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_actual_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mc_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_actual_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_l\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mC_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mc_vecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mc_lens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_actual_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-c88b7fb9ef0d>\u001b[0m in \u001b[0;36mvectorize\u001b[0;34m(sent, fill, clean)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mPADDING\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW2VEC_LEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfill\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mvecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPADDING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "import time\n",
    "\n",
    "def train():\n",
    "    N = (len(q_l) if DATA_CAP is None else DATA_CAP)\n",
    "    itr = 0\n",
    "    \n",
    "    for _ in range(num_epochs):\n",
    "        print(\"Epoch: \", _)\n",
    "        st = time.time()\n",
    "        for batches in np.arange(N/batch_size):\n",
    "            print(batches,\" \", end=\"\")\n",
    "\n",
    "            (q_vecs, q_lens), (c_vecs, c_lens), label_vecs, _ = get_batch(cnt=batch_size)\n",
    "            q_vecs_ip = q_vecs.transpose(1,0,2) #To make it to (time_steps, batch_size, word_vec_len_features) shape\n",
    "            c_vecs_ip = c_vecs.transpose(1,0,2) #To make it to (time_steps, batch_size, word_vec_len_features) shape\n",
    "            label_vecs = label_vecs.reshape(2, batch_size, C_SIZE)\n",
    "#             print(sess.run(c_state, feed_dict={q_batch_ip : q_vecs_ip,\n",
    "#                                                c_batch_ip : c_vecs_ip}))\n",
    "#             sess.run(q_state, feed_dict={q_batch_ip : q_vecs_ip,\n",
    "#                                            c_batch_ip : c_vecs_ip,\n",
    "#                                            labels_ip_train : label_vecs})\n",
    "            \n",
    "            ret = sess.run(loss_train, feed_dict={q_batch_ip : q_vecs_ip,\n",
    "                                                  q_seq_lens_holder : q_lens,\n",
    "                                                  c_seq_lens_holder : c_lens,\n",
    "                                                  c_batch_ip : c_vecs_ip,\n",
    "                                                  labels_ip_train : label_vecs})\n",
    "            itr += 1\n",
    "            if itr % 5 == 0:\n",
    "                end = time.time()\n",
    "                loss = sess.run(loss_train, feed_dict={q_batch_ip : q_vecs_ip,\n",
    "                                                       q_seq_lens_holder : q_lens, \n",
    "                                                       c_seq_lens_holder : c_lens,\n",
    "                                                       c_batch_ip : c_vecs_ip,\n",
    "                                                       labels_ip_train : label_vecs})\n",
    "                em, f1 = get_metrics((q_l, c_l, s_l))\n",
    "                print(\"\\nItr: %s, Loss:%s, Acc:%s, Time:%s\"%(itr, loss, f1, end-st))\n",
    "                st = end\n",
    "\n",
    "#tf.reset_default_graph()\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
